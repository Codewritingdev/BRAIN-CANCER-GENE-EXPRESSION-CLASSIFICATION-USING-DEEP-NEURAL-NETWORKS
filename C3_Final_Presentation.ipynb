{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3 Final Presentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptAM4h-OTjLF"
      },
      "source": [
        "**BRAIN CANCER GENE EXPRESSION CLASSIFICATION USING DEEP NEURAL NETWORKS**\r\n",
        "\r\n",
        "**A Microarray Dataset from CuMiDa**\r\n",
        "\r\n",
        "https://www.kaggle.com/brunogrisci/brain-cancer-gene-expression-cumida?select=Brain_GSE50161.csv\r\n",
        "\r\n",
        "References\r\n",
        "Feltes, B.C.; Chandelier, E.B.; Grisci, B.I.; Dorn, M. (2019) CuMiDa: An Extensively Curated Microarray Database for Benchmarking and Testing of Machine Learning Approaches in Cancer Research. Journal of Computational Biology, 26 (4), 376-386. [https://doi.org/10.1089/cmb.2018.0238]\r\n",
        "\r\n",
        "Grisci, B. I., Feltes, B. C., & Dorn, M. (2019). Neuroevolution as a tool for microarray gene expression pattern identification in cancer research. Journal of biomedical informatics, 89, 122-133. [https://doi.org/10.1016/j.jbi.2018.11.013]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whqiB8NYTjVG"
      },
      "source": [
        "**PROBLEM, CONTEXT, METRICS, STAKEHOLDERS, AND CONSTRAINTS**\r\n",
        "\r\n",
        "I used a carefully curated dataset containing handpicked cancer microarrays from the Gene Expression Omnibus (GEO) and Curated Microarray Database (CuMiDa). The aim of the dataset is to offer homogeneous and state of the art biological preprocessing to propel machine learning studies focused on cancer research. The dataset was downloaded from Kaggle and all processing and modeling work was done in Google Colab in Jupyter Notebooks.\r\n",
        "\r\n",
        "Using the dataset of gene expressions levels for 54675 genes for 5 different types of tissue, we used Principal Component Analysis (PCA) to reduce our data and a Deep Neural Net (Sequential model from Keras) to label types of tissue.\r\n",
        "\r\n",
        "Our goal was to find the number of dimensions we could reduce our data to while still maintaining accuracy and successful use of a DNN to classify tissue. We only used the data contained in the CuMiDa microarrays and our environment was Google Colab (and not Paperspace as outlined in the Project Proposal).\r\n",
        "\r\n",
        "This study is aimed at displaying my skills to my mentor (Devin Cavagnaro from Springboard Data Science Bootcamp) and to potential future employers, as well as those interested in furthering Machine Learning potential in Medicine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ocZYixSTjcb"
      },
      "source": [
        "**DATA WRANGLING AND EXPLORATORY DATA ANALYSIS**\r\n",
        "\r\n",
        "I read the dataset into a Pandas dataframe (note that I had to use `error_bad_lines=True` to be able to see all the data). `df.shape` returned a shape of 130 by 54677 of which one column was not useful to modeling (containing the ID of the samples) and one column of labels (the four types of cancer and 'normal' tissue). \r\n",
        "I saved the results of calling `.describe()` on the dataframe to a new variable and analyzed the mean, std, min and max of the data. Mean shows a normal distribution with a small right tail, whereas standard deviation has a strong right tail. I then found the highest and lowest values for these four statistics. (Note that this is where I has an issue with my Paperspace account and all previous work was lost, and had to switch to Google Colab which is a great tool)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82sVGJawTjjx"
      },
      "source": [
        "**PREPROCESSING, PCA, AND MODELING WITH DNNs**\r\n",
        "\r\n",
        "I imported the required libraries and modules (including sklearn and keras) and read the data into a dataframe. For my X (predictor features) I used the gene expressions, and the type of tissue as my y (predicted labels). I used one-hot encoding on the the labels to transform them to numerical data for modeling. I then split my data into train and test samples and used a scaler to modify the the features. \r\n",
        "I then created a Sequential model with two hidden layers of size 120 and 60 with 'relu' activation for both, and a 'softmax' output layer. I also used PCA to test various components for the features.\r\n",
        "**After fitting and evaluating my model on accuracy, I found that the least minimum viable components for PCA that still gave me 100% accuracy was 20.** The explained variance ratio of the features for 20 components was around 30%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKgu29wPbSgj"
      },
      "source": [
        "pca = PCA(n_components=20)\r\n",
        "pca = pca.fit(X_train_scaled)\r\n",
        "X_train_scaled_pca = pca.transform(X_train_scaled)\r\n",
        "X_test_scaled_pca = pca.transform(X_test_scaled)\r\n",
        "\r\n",
        "\r\n",
        "ncols = X_train_scaled_pca.shape[1]\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(120, input_shape=(ncols,), activation='relu'))\r\n",
        "model.add(Dense(60, activation='relu'))\r\n",
        "model.add(Dense(5, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.fit(X_train_scaled_pca, y_train, epochs=200, batch_size=10, verbose=0)\r\n",
        "scores = model.evaluate(X_test_scaled_pca, y_test)\r\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tnJnM63Tjpj"
      },
      "source": [
        "**CONCLUSION**\r\n",
        "\r\n",
        "I successfully trained a Deep Neural Network to classify Gene Expression data on five different types of brain tissue with 100% accuracy and the number of components needed for PCA was 20. This helped greatly reduce the dimension of the data and proved to be a reliable and accurate predictor for the types of tissue. \r\n",
        "\r\n",
        "I want to thank my mentor for providing help on this project as well as give thanks to various contributors on StackOverflow and TowardsDataScience blog for tips and tricks on creating and tuning the model.\r\n"
      ]
    }
  ]
}